{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd341bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toutes les images ont été redimensionnées et les images initiales ont été supprimées avec succès.\n",
      "Toutes les images ont été redimensionnées et les images initiales ont été supprimées avec succès.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, UnidentifiedImageError\n",
    "import os\n",
    "# Create DataFrames for training and test data\n",
    "TRAIN_DIR = \"C:/Users/bdhia/OneDrive/Bureau/final deep learning/data_set/Data_set1/train\"\n",
    "TEST_DIR = \"C:/Users/bdhia/OneDrive/Bureau/final deep learning/data_set/Data_set1/test\"\n",
    "# Fonction pour redimensionner une image\n",
    "def redimensionner_image(chemin_image, nouvelle_taille, chemin_sortie):\n",
    "    try:\n",
    "        image = Image.open(chemin_image)\n",
    "\n",
    "        # Convertir l'image en mode RVB si elle est en mode RGBA\n",
    "        if image.mode == 'RGBA':\n",
    "            image = image.convert('RGB')\n",
    "\n",
    "        image_redimensionnee = image.resize(nouvelle_taille)\n",
    "        image_redimensionnee.save(chemin_sortie)\n",
    "        image.close()\n",
    "\n",
    "        # Supprimer l'image initiale\n",
    "        os.remove(chemin_image)\n",
    "    except (UnidentifiedImageError, OSError) as e:\n",
    "        print(f\"Erreur lors du traitement de {chemin_image}: {e}\")\n",
    "\n",
    "# Dossier racine train\n",
    "dossier_racine1 = TRAIN_DIR\n",
    "\n",
    "# Spécifier la nouvelle taille en pixels (largeur, hauteur)\n",
    "nouvelle_taille = (128, 128)\n",
    "\n",
    "# Parcourir récursivement les sous-dossiers\n",
    "for dossier_parent, sous_dossiers, fichiers in os.walk(dossier_racine1):\n",
    "    for fichier in fichiers:\n",
    "        if fichier.endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "            chemin_image = os.path.join(dossier_parent, fichier)\n",
    "            chemin_sortie = os.path.join(dossier_parent, \"redimensionnee_\" + fichier)\n",
    "            try:\n",
    "                redimensionner_image(chemin_image, nouvelle_taille, chemin_sortie)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors du traitement de {chemin_image}: {e}\")\n",
    "\n",
    "print(\"Toutes les images ont été redimensionnées et les images initiales ont été supprimées avec succès.\")\n",
    "\n",
    "# Dossier racine test\n",
    "dossier_racine2 = TEST_DIR\n",
    "\n",
    "# Spécifier la nouvelle taille en pixels (largeur, hauteur)\n",
    "nouvelle_taille = (96, 96)\n",
    "\n",
    "# Parcourir récursivement les sous-dossiers\n",
    "for dossier_parent, sous_dossiers, fichiers in os.walk(dossier_racine2):\n",
    "    for fichier in fichiers:\n",
    "        if fichier.endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "            chemin_image = os.path.join(dossier_parent, fichier)\n",
    "            chemin_sortie = os.path.join(dossier_parent, \"redimensionnee_\" + fichier)\n",
    "            try:\n",
    "                redimensionner_image(chemin_image, nouvelle_taille, chemin_sortie)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors du traitement de {chemin_image}: {e}\")\n",
    "\n",
    "print(\"Toutes les images ont été redimensionnées et les images initiales ont été supprimées avec succès.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29d7da56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bdhia\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8ca649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a DataFrame with image paths and labels\n",
    "def create_dataframe(directory):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(directory):\n",
    "        for imagename in os.listdir(os.path.join(directory, label)):\n",
    "            image_paths.append(os.path.join(directory, label, imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    return pd.DataFrame({'image': image_paths, 'label': labels})# Create DataFrames for training and test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d79c01c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n",
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = \"C:/Users/bdhia/OneDrive/Bureau/final deep learning/data_set/Data_set1/train\"\n",
    "TEST_DIR = \"C:/Users/bdhia/OneDrive/Bureau/final deep learning/data_set/Data_set1/test\"\n",
    "train = create_dataframe(TRAIN_DIR)\n",
    "test = create_dataframe(TEST_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cce06ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images, target_size=(128, 128)):\n",
    "    features = []\n",
    "    for image_path in tqdm(images):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Charger l'image en niveaux de gris avec OpenCV\n",
    "        if image is not None:\n",
    "            # Assurez-vous que toutes les images ont les mêmes dimensions avant le redimensionnement\n",
    "            if image.shape[0] != target_size[0] or image.shape[1] != target_size[1]:\n",
    "                image = cv2.resize(image, (target_size[1], target_size[0]))  # OpenCV utilise (largeur, hauteur)\n",
    "            image = np.reshape(image, (target_size[0], target_size[1], 1))\n",
    "            features.append(image)\n",
    "\n",
    "    features = np.array(features)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9d887bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 28696/28696 [00:06<00:00, 4529.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7176/7176 [00:01<00:00, 4954.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess and extract features for training and test data\n",
    "train_features = extract_features(train['image'], target_size=(128, 128))\n",
    "test_features = extract_features(test['image'], target_size=(128, 128))\n",
    "\n",
    "\n",
    "# Normalize the features\n",
    "x_train = train_features / 255.0\n",
    "x_test = test_features / 255.0\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train['label'])\n",
    "y_test = le.transform(test['label'])\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train_encoded = to_categorical(y_train, num_classes=7)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38dcc787",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution des classes avant l'équilibrage:\n",
      "Counter({'happy': 7213, 'neutral': 4964, 'sad': 4828, 'fear': 4097, 'angry': 3988, 'surprise': 3170, 'disgust': 436})\n"
     ]
    }
   ],
   "source": [
    "# Display the distribution of classes before balancing\n",
    "print(\"Distribution des classes avant l'équilibrage:\")\n",
    "print(Counter(train['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11fa0e65",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.16 GiB for an array with shape (50491, 16384) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m x_train_reshaped \u001b[38;5;241m=\u001b[39m x_train\u001b[38;5;241m.\u001b[39mreshape(x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m oversampler \u001b[38;5;241m=\u001b[39m RandomOverSampler(sampling_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m oversampler\u001b[38;5;241m.\u001b[39mfit_resample(x_train_reshaped, y_train)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Display the distribution of classes after balancing\u001b[39;00m\n\u001b[0;32m      7\u001b[0m balanced_distribution \u001b[38;5;241m=\u001b[39m Counter(y_resampled)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_resample(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\base.py:112\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m    110\u001b[0m )\n\u001b[1;32m--> 112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n\u001b[0;32m    114\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    116\u001b[0m )\n\u001b[0;32m    118\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\over_sampling\\_random_over_sampler.py:247\u001b[0m, in \u001b[0;36mRandomOverSampler._fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    245\u001b[0m     X_resampled \u001b[38;5;241m=\u001b[39m sparse\u001b[38;5;241m.\u001b[39mvstack(X_resampled, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mformat)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 247\u001b[0m     X_resampled \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(X_resampled)\n\u001b[0;32m    248\u001b[0m y_resampled \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack(y_resampled)\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_resampled, y_resampled\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\shape_base.py:296\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    295\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 6.16 GiB for an array with shape (50491, 16384) and data type float64"
     ]
    }
   ],
   "source": [
    "# Oversample the training data to balance classes\n",
    "x_train_reshaped = x_train.reshape(x_train.shape[0], -1)\n",
    "oversampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = oversampler.fit_resample(x_train_reshaped, y_train)\n",
    "\n",
    "# Display the distribution of classes after balancing\n",
    "balanced_distribution = Counter(y_resampled)\n",
    "print(\"\\nDistribution des classes après l'équilibrage:\")\n",
    "print(balanced_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b41bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the balanced data and split into training and validation sets\n",
    "X_resampled, y_resampled = shuffle(X_resampled, y_resampled, random_state=42)\n",
    "x_train_resampled, x_val_resampled, y_train_resampled, y_val_resampled = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42\n",
    ")\n",
    "# Remodeler les caractéristiques à la forme attendue\n",
    "x_train_resampled = x_train_resampled.reshape(x_train_resampled.shape[0], 128, 128, 1)\n",
    "x_val_resampled = x_val_resampled.reshape(x_val_resampled.shape[0], 128, 128, 1)\n",
    "\n",
    "# Encodage one-hot des étiquettes pour les données équilibrées\n",
    "y_train_resampled_encoded = to_categorical(y_train_resampled, num_classes=7)\n",
    "y_val_resampled_encoded = to_categorical(y_val_resampled, num_classes=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7239a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a learning rate schedule function\n",
    "def lr_schedule(epoch):\n",
    "    initial_learning_rate = 0.001\n",
    "    decay_factor = 0.7\n",
    "    decay_steps = 4 # Adjust this value based on your experimentation\n",
    "    return initial_learning_rate * decay_factor**(epoch // decay_steps)\n",
    "# Set up the LearningRateScheduler callback\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c37679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', input_shape=(128, 128, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))  # Adjust dropout_rate here\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))  # Adjust dropout_rate here\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))  # Adjust dropout_rate here\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))  # Adjust dropout_rate here\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))  # Adjust dropout_rate here\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f850d7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d4e366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31061fae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79571371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70f737d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171bb3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd646ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e12d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc5ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf2bfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5062b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
